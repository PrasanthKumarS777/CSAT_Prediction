# âš¡ DeepCSAT â€” Customer Satisfaction Score Prediction Engine

<div align="center">

![Python](https://img.shields.io/badge/Python-3.11+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-1.40.0-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)
![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-ML-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.20-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)
![CatBoost](https://img.shields.io/badge/CatBoost-Regression-yellow?style=for-the-badge)
![XGBoost](https://img.shields.io/badge/XGBoost-Regression-blue?style=for-the-badge)
![ANN](https://img.shields.io/badge/ANN-Deep%20Learning-purple?style=for-the-badge)
![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)

**A deep learning-powered analytical dashboard that predicts CSAT scores from 85,907 e-commerce customer support interaction records â€” enabling real-time service quality insight.**

ğŸ”— **[Live Demo â†’ prasanthkumars777-csat-prediction-app-ig5nuc.streamlit.app](https://prasanthkumars777-csat-prediction-app-ig5nuc.streamlit.app/)**

</div>

---

## ğŸ“Œ Project Overview

**DeepCSAT** is an end-to-end machine learning and deep learning project built on a real-world eCommerce customer support dataset from a platform named **Shopzilla**. It combines exploratory data analysis, NLP preprocessing, feature engineering, PCA dimensionality reduction, and four models â€” CatBoost, Random Forest, XGBoost, and a Deep Learning **Artificial Neural Network (ANN)** â€” into a fully interactive Streamlit dashboard.

The goal: **predict customer satisfaction (CSAT) scores** from interaction metadata, enabling businesses to proactively identify and fix service quality issues before they escalate.

---

## ğŸ–¥ï¸ Dashboard Pages

| Page | Description |
|------|-------------|
| ğŸ  **Overview** | KPI cards, satisfaction gauge, score distribution, ML pipeline steps |
| ğŸ” **Data Explorer** | Raw data preview, column info, missing value analysis, statistics |
| ğŸ“Š **EDA** | 14 interactive charts â€” univariate, bivariate, multivariate analysis |
| ğŸ§ª **Hypothesis Testing** | ANOVA, Welch t-test, Chi-Square with violin plots and heatmaps |
| âš™ï¸ **Feature Engineering** | ExtraTrees importance, PCA variance explained, NLP pipeline steps |
| ğŸ¤– **Models** | Live training of CatBoost, Random Forest, XGBoost, and ANN with residual plots |
| ğŸ† **Comparison** | Side-by-side MSE/RÂ² bar charts, performance radar chart across all 4 models |
| ğŸ”® **Predictor** | Real-time CSAT prediction from user-input interaction details |
| ğŸ“¥ **Export & Report** | Download cleaned CSV, model metrics, auto-generated summary report |

---

## ğŸ§  ML + Deep Learning Pipeline

```
Raw CSV (85,907 rows)
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Cleaning      â”‚  lowercase, strip, null handling
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Feature Engineeringâ”‚  datetime features, response_time_hrs
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Label Encoding     â”‚  channel, category, shift, tenure, etc.
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NLP Pipeline       â”‚  contractions â†’ lowercase â†’ punctuation
â”‚                     â”‚  â†’ URL strip â†’ stopwords â†’ TF-IDF (100)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ExtraTrees         â”‚  top-8 feature selection
â”‚  Feature Selection  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  StandardScaler     â”‚  zero mean / unit variance
â”‚  + PCA (10 comps)   â”‚  captures ~variance of dataset
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Train/Test Split   â”‚  80% train / 20% test, random_state=42
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼         â–¼            â–¼            â–¼
CatBoost  Random Forest  XGBoost      ANN
                                  (Deep Learning)
                               256â†’128â†’64â†’32
                            BatchNorm + Dropout
                            Adam + EarlyStopping
    â”‚         â”‚            â”‚            â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
  MSE Â· RÂ² Â· RMSE Â· Radar Chart
```

---

## ğŸ¤– Models

| Model | Type | Key Parameters |
|-------|------|----------------|
| **CatBoost** | Gradient Boosting | depth=5, iterations=100, lr=0.1 |
| **Random Forest** | Ensemble | n_estimators=100, max_depth=10 |
| **XGBoost** | Gradient Boosting | n_estimators=100, lr=0.1, max_depth=5 |
| **ANN** | Deep Learning (MLP) | 256â†’128â†’64â†’32, ReLU, Adam, EarlyStopping |

The **ANN** is a 4-layer feedforward Artificial Neural Network with:
- `BatchNormalization` after each hidden layer for stable training
- `Dropout` (0.3 / 0.2 / 0.1) to prevent overfitting
- `Adam` optimizer with learning rate 0.001
- `EarlyStopping` with patience=15 to avoid overtraining
- Trained using `TensorFlow/Keras` in `file.py` and `sklearn MLPRegressor` in `app.py`

---

## ğŸ“Š Hypothesis Tests

| Test | Variables | Result |
|------|-----------|--------|
| **ANOVA** | Channel Name vs CSAT | âœ… Channel significantly affects CSAT |
| **Welch t-test** | Item Price (High/Low) vs CSAT | âœ… Price range influences satisfaction |
| **Chi-Square** | Agent Shift vs CSAT | âœ… Shift timing affects CSAT |

---

## ğŸ—‚ï¸ Project Structure

```
CSAT_Prediction/
â”‚
â”œâ”€â”€ app.py                          # Streamlit dashboard (main app)
â”œâ”€â”€ file.py                         # Standalone ML + Deep Learning pipeline
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ README.md                       # This file
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ eCommerce_Customer_support_data.csv   # Raw dataset (85,907 rows)
â”‚
â”œâ”€â”€ outputs/                        # EDA + model charts (generated by file.py)
â”‚   â”œâ”€â”€ 01_csat_distribution.png
â”‚   â”œâ”€â”€ 02_channel_distribution.png
â”‚   â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ 23_ann_baseline.png
â”‚   â”œâ”€â”€ 24_ann_tuned.png
â”‚   â”œâ”€â”€ 25_ann_loss_curve.png
â”‚   â”œâ”€â”€ 26_catboost_feature_importance.png
â”‚   â””â”€â”€ 27_model_comparison.png     # All 4 models compared
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ ann_tuned.keras             # Saved ANN model (generated by file.py)
â”‚
â””â”€â”€ catboost_info/                  # CatBoost training logs
```

---

## ğŸš€ Getting Started

### 1. Clone the repository

```bash
git clone https://github.com/PrasanthKumarS777/CSAT_Prediction.git
cd CSAT_Prediction
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

### 3. Add the dataset

Place the CSV file inside the `data/` folder:

```
data/eCommerce_Customer_support_data.csv
```

### 4. Run the Streamlit dashboard

```bash
streamlit run app.py
```

### 5. (Optional) Run the standalone ML + Deep Learning pipeline

```bash
python file.py
```

This generates all 27 EDA + model comparison charts in `outputs/` and saves the trained ANN model to `models/ann_tuned.keras`.

---

## ğŸ“¦ Requirements

```
streamlit>=1.40.0
pandas
numpy
plotly
scikit-learn
scipy
catboost
xgboost
tensorflow>=2.20.0
nltk
```

Install everything at once:

```bash
pip install streamlit pandas numpy plotly scikit-learn scipy catboost xgboost tensorflow nltk
```

> âš ï¸ **Note:** TensorFlow 2.20 upgrades `protobuf` to v7 which conflicts with Streamlit. Fix with:
> ```bash
> pip install "protobuf>=5.28.0,<6.0.0"
> pip install "packaging>=20,<25"
> ```

---

## ğŸ“ˆ Dataset

| Property | Value |
|----------|-------|
| Source | eCommerce Customer Support Interactions (Shopzilla) |
| Rows | 85,907 |
| Columns | 20 |
| Target | CSAT Score (1â€“5) |
| Missing Data | ~25.4% overall |
| Duplicates | 0 |

**Key columns:** `channel_name`, `category`, `Sub-category`, `Agent Shift`, `Tenure Bucket`, `Agent_name`, `Issue_reported at`, `issue_responded`, `Item_price`, `CSAT Score`, `Customer Remarks`

---

## ğŸ”® Live Predictor

The **Predictor** page lets you input real interaction details and get an instant predicted CSAT score:

- Select channel, shift, tenure, category
- Set reported/responded hour and day of week
- Set response time in hours
- Click **ğŸ”® Predict CSAT Score**

The best-performing model (by RÂ²) across all four models is automatically selected for prediction.

---

## ğŸ‘¤ Author

**Prasanth Kumar Sahu**

[![GitHub](https://img.shields.io/badge/GitHub-PrasanthKumarS777-181717?style=flat-square&logo=github)](https://github.com/PrasanthKumarS777)

---

## ğŸ“„ License

This project is licensed under the MIT License â€” feel free to use, modify, and distribute.

---

<div align="center">
  <sub>Built with â¤ï¸ using Streamlit Â· Plotly Â· Scikit-Learn Â· CatBoost Â· XGBoost Â· TensorFlow Â· Keras</sub>
</div>